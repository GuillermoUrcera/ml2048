{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting with new model\n",
      "Replaying\n",
      "Making logs\n",
      "Saving model\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nCLogCEJGEEEXBEHICCLogiAIGeH/AyVDADmszoAcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1303b1320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import puzzle\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "MAX_EPISODES=3000\n",
    "INDEX_EPISODE=0\n",
    "INDEX_EPOCH=1\n",
    "INDEX_REWARD=2\n",
    "INDEX_LOSS=3\n",
    "INDEX_SCORE=4\n",
    "INDEX_INCREMENT=5\n",
    "INDEX_LOST=6\n",
    "INDEX_LAST_STATE=7\n",
    "INDEX_ACTION=8\n",
    "INDEX_CURRENT_STATE=9\n",
    "INDEX_WEIGHTS=10\n",
    "LOG_LOCATION='../logs/log.csv'\n",
    "LOG_ITERATION=100 # Logs after this many global iterations\n",
    "#ACCESS SCORE AS self.game.score\n",
    "#ACCESS MATRIX AS self.game.matrix\n",
    "#DECIDE ACTION TO TAKE IN act()\n",
    "#POSSIBLE ACTIONS:\n",
    "#\tgo up:\t\t\"'w'\"\n",
    "#\tgo left:\t\"'a'\"\n",
    "#\tgo right:\t\"'s'\"\n",
    "#\tgo down:\t\"'d'\"\n",
    "\n",
    "# To start from scratch, no inputs are needed when creating a new machine.\n",
    "# If you want to continue from a previous model, initiate with parameter model='load'\n",
    "# The machine will then start from the model file placed in : '../logs/my_model.h5'\n",
    "\n",
    "class Machine():\n",
    "    game=puzzle.GameGrid() # Game object\n",
    "    epoch=0\n",
    "    episode=0\n",
    "    loss=0\n",
    "    reward=0\n",
    "    verbose_logging=False\n",
    "    weight_logging=False\n",
    "    action=\"'w'\"\n",
    "    model = Sequential()\n",
    "    inputVector=np.zeros((1, 4))\n",
    "    lastState=np.zeros((1, 4))\n",
    "    Qvalues0=np.zeros((1,4))\n",
    "    Qvalues1=np.zeros((1,4))\n",
    "    acts = [\"'w'\",\"'s'\",\"'d'\",\"'a'\"]\n",
    "    gamma = 0.9    # Discount rate\n",
    "    epsilon = 0.99  # Exploration rate\n",
    "    iteration = 0\n",
    "    log_iteration=0\n",
    "    dump=False\n",
    "    buffer=np.zeros((1,7))\n",
    "    bufferShape=np.zeros((1,7))\n",
    "    def __init__(self, verbose_logging_in=False,weight_logging_in=False, model='new'):\n",
    "        # Short time memory\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        #self.gamma = 0.9    # discount rate\n",
    "        self.e_decay = .99\n",
    "        self.e_min = 0.05\n",
    "        \n",
    "        self.dump=False\n",
    "        self.verbose_logging=verbose_logging_in\n",
    "        self.weight_logging=weight_logging_in\n",
    "        # Create model\n",
    "        self.createModel(model)\n",
    "        # Initialise log\n",
    "        with open('../logs/log.csv', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            if self.verbose_logging and self.weight_logging:\n",
    "                writer.writerow([\"EPISODE\",\"EPOCH\",\"REWARD\",\"LOSS\",\"TOTAL SCORE\",\"INCREMENT IN SCORE\",\"LOST\",\"LAST STATE\",\"ACTION\",\"CURRENT STATE\",\"WEIGHTS\"]) \n",
    "                self.bufferShape=np.zeros((1,11))\n",
    "            elif self.verbose_logging:\n",
    "                writer.writerow([\"EPISODE\",\"EPOCH\",\"LAST STATE\",\"ACTION\",\"CURRENT STATE\",\"REWARD\",\"LOSS\",\"TOTAL SCORE\",\"INCREMENT IN SCORE\",\"LOST\"])\n",
    "                self.bufferShape=np.zeros((1,10))\n",
    "            else:\n",
    "                writer.writerow([\"EPISODE\",\"EPOCH\",\"REWARD\",\"LOSS\",\"TOTAL SCORE\",\"INCREMENT IN SCORE\",\"LOST\"]) \n",
    "                self.bufferShape=np.zeros((1,7))\n",
    "        self.buffer=self.bufferShape\n",
    "        self.buffer=self.buffer.tolist()\n",
    "    def createModel(self, model):\n",
    "        if model == 'new':\n",
    "            answer = str(input(\"Are you sure you want to start from scratch and delete the current model? (y/n): \"))\n",
    "            if answer == 'y': \n",
    "                print(\"Creating new model\")\n",
    "                self.model.add(Dense(20, input_dim=9, activation='tanh')) # Adds the first layer with 16 inputs\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "                self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')                \n",
    "                self.model.add(Dense(4, activation='linear'))             # Adds output layer with 20 nodes\n",
    "                self.model.compile(loss='mse',optimizer=RMSprop(lr=0.5)) # Creates the model from all of the above\n",
    "            if answer == 'n':\n",
    "                print(\"Using old model\")\n",
    "                self.model = load_model('../logs/my_model.h5')\n",
    "            if (answer != 'y') and (answer != 'n') : \n",
    "                print('Invalid answer')\n",
    "        if model == 'load':\n",
    "            self.model = load_model('../logs/my_model.h5')\n",
    "    def run(self):\n",
    "        # Transform game state to 1D array\n",
    "        for i in range(2):\n",
    "            self.inputVector[0][0+2*i:2+2*i]=self.game.matrix[i]\n",
    "        self.epoch=self.epoch+1 # Increase epoch\n",
    "        self.iteration=self.iteration+1 # Increase global iteration\n",
    "        self.log_iteration=self.log_iteration+1\n",
    "        self.log() # Log model\n",
    "        self.game.increment=self.get_reward() # Update reward if game has been lost\n",
    "        self.game.key_down(self.act()) # Select action and update weights\n",
    "        self.lastState=self.inputVector # For logging\n",
    "        # Game loop\n",
    "        self.game.update_idletasks\n",
    "        self.game.update()\n",
    "        # remember previous actions\n",
    "        self.remember() \n",
    "        # pool emaG\n",
    "    def act(self):\n",
    "        if random.random() >= self.epsilon:  # Exploration\n",
    "            #print(\" Random Action \")\n",
    "            self.action = self.acts[random.randint(0,3)]\n",
    "            return self.action\n",
    "        else: \n",
    "            # Predict Q values of current state\n",
    "            self.Qvalues1[0]=self.gamma*self.model.predict(self.inputVector)+self.game.increment\n",
    "            # Extract Q value of the state\n",
    "            Q1=np.amax(self.Qvalues1)\n",
    "            Q1_index=self.Qvalues1.argmax()\n",
    "            #Construct target vector\n",
    "            self.Qvalues1=self.Qvalues0\n",
    "            self.Qvalues1[0][Q1_index]=Q1\n",
    "            # Update weights with respect to last step's prediction of this step's Q values\n",
    "            self.loss=self.model.train_on_batch(self.lastState, self.Qvalues1)\n",
    "            # Make this step's Q values next step's past Q values\n",
    "            #self.Qvalues0=self.Qvalues1\n",
    "            self.Qvalues0=self.gamma*self.model.predict(self.inputVector)+self.game.increment\n",
    "            # Select action with highest Q value\n",
    "            self.action=self.acts[self.Qvalues0.argmax()] # Don't delete this variable, it's used when logging\n",
    "            return self.action\n",
    "        \n",
    "    # memorize state; action; reward; next state ??inputVector == next state??\n",
    "    def remember(self):\n",
    "        self.memory.append((self.lastState, self.Qvalues1.argmax(), self.reward, self.inputVector, self.game.result))\n",
    "        \n",
    "    # replay some of the actions at the end of training    \n",
    "    def replay(self, batch_size, state_size, action_size):\n",
    "        batch_size = min(batch_size, len(self.memory))\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        X = np.zeros((batch_size, state_size))\n",
    "        Y = np.zeros((batch_size, action_size))\n",
    "        for i in range(batch_size):\n",
    "            state, action, reward, next_state, done = minibatch[i]\n",
    "            target = self.model.predict(state)[0]\n",
    "            if done:\n",
    "                target[action] = reward\n",
    "            else:\n",
    "                target[action] = reward + self.gamma * np.amax(self.model.predict(next_state)[0])\n",
    "            X[i], Y[i] = state, target\n",
    "        self.model.fit(X, Y, batch_size=batch_size, epochs=1, verbose=0)\n",
    "        if self.epsilon > self.e_min:\n",
    "            self.epsilon *= self.e_decay\n",
    "            \n",
    "    def log(self):\n",
    "        # Log episode, epoch, reward, error, score, increment in score, lost, previous state, action, next state, weights \n",
    "        if self.weight_logging:\n",
    "            for layer in self.model.layers:\n",
    "                weights = layer.get_weights() # list of numpy arrays\n",
    "        if self.weight_logging and self.verbose_logging:\n",
    "            self.buffer.append([self.episode,self.epoch,self.reward,self.loss,self.game.score,self.game.increment,self.game.result,self.lastState,self.action,self.inputVector,weights])\n",
    "        elif self.verbose_logging:\n",
    "            self.buffer.append([self.episode,self.epoch,self.reward,self.loss,self.game.score,self.game.increment,self.game.result,self.lastState,self.action,self.inputVector])\n",
    "        else:\n",
    "            self.buffer.append([self.episode,self.epoch,self.reward,self.loss,self.game.score,self.game.increment,self.game.result])\n",
    "        if (self.log_iteration == LOG_ITERATION) or self.dump:\n",
    "            with open(LOG_LOCATION, 'a', newline='') as csvfile:\n",
    "                self.buffer=self.buffer[1:] # Remove first line of zeros               \n",
    "                writer = csv.writer(csvfile)\n",
    "                for row in self.buffer:\n",
    "                    writer.writerow(row)\n",
    "                # Reset buffer\n",
    "                self.buffer=self.bufferShape\n",
    "                self.buffer=self.buffer.tolist()\n",
    "                self.log_iteration=0\n",
    "    def dump_logs(self):\n",
    "        self.dump=True\n",
    "        self.log()\n",
    "    def plot(self):         \n",
    "        with open(LOG_LOCATION,newline='') as csvfile:\n",
    "            reader=csv.reader(csvfile)\n",
    "            # Transform reader to array\n",
    "            data=list(reader) \n",
    "            # Allocate arrays\n",
    "            x=[]\n",
    "            y=[]\n",
    "            # Get rid of labels\n",
    "            a=data.pop(0)\n",
    "            for row in data:\n",
    "                # Search for lost games\n",
    "                if row[INDEX_LOST]==\"True\": # Needed because it's read as a string and not a bool\n",
    "                    x.append(row[INDEX_EPISODE]) # Episode\n",
    "                    y.append(row[INDEX_SCORE]) # Total score     \n",
    "            # Plot results\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(x, y)\n",
    "    def get_reward(self):\n",
    "        l=0\n",
    "        if self.game.result: # If the agent lost\n",
    "            l = -2*self.game.increment-self.game.score\n",
    "            # Reset game\n",
    "            self.game.reset()\n",
    "            self.epoch=0\n",
    "            self.episode=self.episode+1\n",
    "        self.reward=self.game.increment + l # Don't delete this variable, it's used for logging\n",
    "        return (self.reward)\n",
    "    def saveModel(self):\n",
    "        self.model.save('../logs/my_model.h5')\n",
    "    \n",
    "print('Starting with new model')\n",
    "our_machine = Machine(model='new')\n",
    "while our_machine.episode<MAX_EPISODES:\n",
    "    our_machine.run()\n",
    "    \n",
    "# replay previous actions\n",
    "print('Replaying')\n",
    "our_machine.replay(32, 4, 4)\n",
    "\n",
    "# Making logs\n",
    "print('Making logs')\n",
    "our_machine.dump_logs()\n",
    "our_machine.plot()\n",
    "\n",
    "# Save model\n",
    "print('Saving model')\n",
    "our_machine.saveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting new training with same model\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3421e9a6e11e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mour_machine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMachine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'load'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0mour_machine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepisode\u001b[0m\u001b[0;34m<\u001b[0m\u001b[0mMAX_EPISODES\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mour_machine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Making logs from double training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-79d5c65d1372>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;31m# Game loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate_idletasks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m         \u001b[0;31m# remember previous actions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremember\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda/lib/python3.6/tkinter/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1170\u001b[0m         \u001b[0;34m\"\"\"Enter event loop until all pending events have been processed by Tcl.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1171\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'update'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1172\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mupdate_idletasks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1173\u001b[0m         \"\"\"Enter event loop until all idle callbacks have been called. This\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Starting new training with same model\n",
    "print('Starting new training with same model')\n",
    "\n",
    "our_machine = Machine(model='load')\n",
    "while our_machine.episode<MAX_EPISODES:\n",
    "    our_machine.run()\n",
    "\n",
    "# Making logs from double training\n",
    "print('Making logs')\n",
    "our_machine.dump_logs()\n",
    "our_machine.plot()\n",
    "\n",
    "# restart Kernel\n",
    "# import IPython, time\n",
    "# time.sleep(2)\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_EPISODES=500\n",
    "\n",
    "# Starting new training with same model\n",
    "print('Starting new training with same model')\n",
    "\n",
    "our_machine = Machine(model='load')\n",
    "while our_machine.episode<MAX_EPISODES:\n",
    "    our_machine.run()\n",
    "\n",
    "# Making logs from double training\n",
    "print('Making logs')\n",
    "our_machine.dump_logs()\n",
    "our_machine.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "MAX_EPISODES=500\n",
    "\n",
    "# Starting new training with same model\n",
    "print('Starting new training with same model')\n",
    "\n",
    "our_machine = Machine(model='load')\n",
    "while our_machine.episode<MAX_EPISODES:\n",
    "    our_machine.run()\n",
    "\n",
    "# Making logs from double training\n",
    "print('Making logs')\n",
    "our_machine.dump_logs()\n",
    "our_machine.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model\n",
    "print('Saving model')\n",
    "our_machine.saveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
