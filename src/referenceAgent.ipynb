{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reward function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import puzzle\n",
    "\n",
    "def reward(self):\n",
    "    increment = self.game.increment\n",
    "    totalScore = self.game.totalScore\n",
    "    # loose does not work yet\n",
    "    #loose = self.game.loose\n",
    "    return increment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "\n",
    "class DQNAgent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.memory = deque(maxlen=100000)\n",
    "        self.gamma = 0.9    # discount rate\n",
    "        self.epsilon = 1.0  # exploration rate\n",
    "        self.e_decay = .99\n",
    "        self.e_min = 0.05\n",
    "        self.learning_rate = 0.01\n",
    "        self.model = self._build_model()\n",
    "\n",
    "    def _build_model(self):\n",
    "        # Neural Net for Deep-Q learning Model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(20, input_dim=self.state_size, activation='tanh')) # Adds the first layer with 16 inputs\n",
    "        model.add(Dense(20, activation='tanh', init='uniform')) # Adds Hidden layer with 20 nodes\n",
    "        model.add(Dense(self.action_size, activation='linear')) # Adds output layer with 2 nodes\n",
    "        model.compile(loss='mse',\n",
    "                      optimizer=RMSprop(lr=self.learning_rate)) # Creates the model from all of the above\n",
    "        return model\n",
    "\n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "\n",
    "    def act(self, state):\n",
    "        if np.random.rand() <= self.epsilon:\n",
    "            return random.randrange(self.action_size)\n",
    "        act_values = self.model.predict(state)\n",
    "        return np.argmax(act_values[0])  # returns action\n",
    "\n",
    "    def replay(self, batch_size):\n",
    "        batch_size = min(batch_size, len(self.memory))\n",
    "        minibatch = random.sample(self.memory, batch_size)\n",
    "        X = np.zeros((batch_size, self.state_size))\n",
    "        Y = np.zeros((batch_size, self.action_size))\n",
    "        for i in range(batch_size):\n",
    "            state, action, reward, next_state, done = minibatch[i]\n",
    "            target = self.model.predict(state)[0]\n",
    "            if done:\n",
    "                target[action] = reward\n",
    "            else:\n",
    "                target[action] = reward + self.gamma * \\\n",
    "                            np.amax(self.model.predict(next_state)[0])\n",
    "            X[i], Y[i] = state, target\n",
    "        self.model.fit(X, Y, batch_size=batch_size, nb_epoch=1, verbose=0)\n",
    "        if self.epsilon > self.e_min:\n",
    "            self.epsilon *= self.e_decay\n",
    "\n",
    "    def load(self, name):\n",
    "        self.model.load_weights(name)\n",
    "\n",
    "    def save(self, name):\n",
    "        self.model.save_weights(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Game execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niIhEKQWAiEiUUgCIiEQpBYCISJT6/9FgGSAFiMsLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5b8cdda048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import time\n",
    "import puzzle\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import RMSprop\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "MAX_EPISODES=10\n",
    "INDEX_EPISODE=0\n",
    "INDEX_EPOCH=1\n",
    "INDEX_REWARD=2\n",
    "INDEX_LOSS=3\n",
    "INDEX_SCORE=4\n",
    "INDEX_INCREMENT=5\n",
    "INDEX_LOST=6\n",
    "INDEX_LAST_STATE=7\n",
    "INDEX_ACTION=8\n",
    "INDEX_CURRENT_STATE=9\n",
    "INDEX_WEIGHTS=10\n",
    "#ACCESS SCORE AS self.game.score\n",
    "#ACCESS MATRIX AS self.game.matrix\n",
    "#DECIDE ACTION TO TAKE IN act()\n",
    "#POSSIBLE ACTIONS:\n",
    "#\tgo up:\t\t\"'w'\"\n",
    "#\tgo left:\t\"'a'\"\n",
    "#\tgo right:\t\"'s'\"\n",
    "#\tgo down:\t\"'d'\"\n",
    "\n",
    "class Machine:\n",
    "    game=puzzle.GameGrid() # Game object\n",
    "    epoch=0\n",
    "    episode=0\n",
    "    loss=0\n",
    "    reward=0\n",
    "    verbose_logging=False\n",
    "    weight_logging=False\n",
    "    action=\"'w'\"\n",
    "    model = Sequential()\n",
    "    inputVector=np.zeros((1, 16))\n",
    "    lastState=np.zeros((1, 16))\n",
    "    Qvalues0=np.zeros((1,4))\n",
    "    Qvalues1=np.zeros((1,4))\n",
    "    acts = [\"'w'\",\"'s'\",\"'d'\",\"'a'\"]\n",
    "    gamma = 0.9    # Discount rate\n",
    "    epsilon = 0.9  # Exploration rate\n",
    "    \n",
    "    def __init__(self, verbose_logging_in=False,weight_logging_in=False):\n",
    "        self.verbose_logging=verbose_logging_in\n",
    "        self.weight_logging=weight_logging_in\n",
    "        # Create model\n",
    "        self.model.add(Dense(20, input_dim=16, activation='tanh')) # Adds the first layer with 16 inputs\n",
    "        self.model.add(Dense(20, activation='tanh'))              # Adds Hidden layer with 20 nodes (Removed 'uniform')\n",
    "        self.model.add(Dense(4, activation='linear'))             # Adds output layer with 20 nodes\n",
    "        self.model.compile(loss='mse',optimizer=RMSprop(lr=0.01)) # Creates the model from all of the above\n",
    "        # Initialise log\n",
    "        with open('../logs/log.csv', 'w', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            if self.verbose_logging and self.weight_logging:\n",
    "                writer.writerow([\"EPISODE\",\"EPOCH\",\"REWARD\",\"LOSS\",\"TOTAL SCORE\",\"INCREMENT IN SCORE\",\"LOST\",\"LAST STATE\",\"ACTION\",\"CURRENT STATE\",\"WEIGHTS\"]) \n",
    "            elif self.verbose_logging:\n",
    "                writer.writerow([\"EPISODE\",\"EPOCH\",\"LAST STATE\",\"ACTION\",\"CURRENT STATE\",\"REWARD\",\"LOSS\",\"TOTAL SCORE\",\"INCREMENT IN SCORE\",\"LOST\"]) \n",
    "            else:\n",
    "                writer.writerow([\"EPISODE\",\"EPOCH\",\"REWARD\",\"LOSS\",\"TOTAL SCORE\",\"INCREMENT IN SCORE\",\"LOST\"]) \n",
    "    def run(self):\n",
    "        # Transform game state to 1D array\n",
    "        for i in range(4):\n",
    "            self.inputVector[0][0+4*i:4+4*i]=self.game.matrix[i]\n",
    "        self.epoch=self.epoch+1 # Increase epoch\n",
    "        self.log() # Log model\n",
    "        self.game.increment=self.get_reward() # Update reward if game has been lost\n",
    "        self.game.key_down(self.act()) # Select action and update weights\n",
    "        self.lastState=self.inputVector # For logging\n",
    "        # Game loop\n",
    "        self.game.update_idletasks\n",
    "        self.game.update()\n",
    "        # pool emaG\n",
    "    def act(self):\n",
    "        if random.random() <= self.epsilon:  # Exploration\n",
    "            #print(\" Random Action \")\n",
    "            self.action = self.acts[random.randint(0,3)]\n",
    "            return self.action\n",
    "        else: \n",
    "            # Predict Q values of current state\n",
    "            self.Qvalues1[0]=self.gamma*self.model.predict(self.inputVector)+self.game.increment\n",
    "            # Update weights with respect to last step's prediction of this step's Q values\n",
    "            self.loss=self.model.train_on_batch(self.inputVector, self.Qvalues0)\n",
    "            # Make this step's Q values next step's past Q values\n",
    "            self.Qvalues0=self.Qvalues1\n",
    "            # Select action with highest Q value\n",
    "            self.action=self.acts[self.Qvalues1.argmax()] # Don't delete this variable, it's used when logging\n",
    "            return self.action\n",
    "    def log(self):\n",
    "        # Log episode, epoch, reward, error, score, increment in score, lost, previous state, action, next state, weights \n",
    "        if self.weight_logging:\n",
    "            for layer in self.model.layers:\n",
    "                weights = layer.get_weights() # list of numpy arrays\n",
    "        with open('../logs/log.csv', 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            if self.weight_logging and self.verbose_logging:\n",
    "                writer.writerow([self.episode,self.epoch,self.reward,self.loss,self.game.score,self.game.increment,self.game.result,self.lastState,self.action,self.inputVector,weights])\n",
    "            elif self.verbose_logging:\n",
    "                writer.writerow([self.episode,self.epoch,self.reward,self.loss,self.game.score,self.game.increment,self.game.result,self.lastState,self.action,self.inputVector])\n",
    "            else:\n",
    "                writer.writerow([self.episode,self.epoch,self.reward,self.loss,self.game.score,self.game.increment,self.game.result]) \n",
    "    def plot(self):         \n",
    "        with open('../logs/log.csv',newline='') as csvfile:\n",
    "            reader=csv.reader(csvfile)\n",
    "            # Transform reader to array\n",
    "            data=list(reader) \n",
    "            # Allocate arrays\n",
    "            x=[]\n",
    "            y=[]\n",
    "            # Get rid of labels\n",
    "            a=data.pop(0)\n",
    "            for row in data:\n",
    "                # Search for lost games\n",
    "                if row[INDEX_LOST]==\"True\": # Needed because it's read as a string and not a bool\n",
    "                    x.append(row[INDEX_EPISODE]) # Episode\n",
    "                    y.append(row[INDEX_SCORE]) # Total score     \n",
    "            # Plot results\n",
    "            fig, ax = plt.subplots()\n",
    "            ax.plot(x, y)\n",
    "    def get_reward(self):\n",
    "        l=0\n",
    "        if self.game.result: # If the agent lost\n",
    "            l = -2*self.game.increment-self.game.score/4\n",
    "            # Reset game\n",
    "            self.game.reset()\n",
    "            self.epoch=0\n",
    "            self.episode=self.episode+1\n",
    "        self.reward=self.game.increment + l # Don't delete this vriable, it's used for logging\n",
    "        return (self.reward)\n",
    "    \n",
    "    #######################################\n",
    "    # I made this function to calculate the best next step. This will be the function\n",
    "    # Determening which state to be given to the neural network.\n",
    "    # This is a bad implementation since it relies on copying the whole game for every\n",
    "    # calculation, but it will work to train in the beginning. \n",
    "    def calculateNextStep(self, game):\n",
    "        best_qval = 0\n",
    "        best_move = 'up' # Default move\n",
    "        acts = ['up','down','right','left']\n",
    "        for act in acts: \n",
    "            game_copy = game\n",
    "            game_copy.key_down(self.act(act))\n",
    "            self.game.update_idletasks\n",
    "            self.game.update()\n",
    "            qval = game_copy.reward()\n",
    "            if qval > best_qval:\n",
    "                best_qval = qval\n",
    "                best_move = act\n",
    "        return best_move\n",
    "    #######################################\n",
    "        \n",
    "our_machine = Machine(True)\n",
    "while our_machine.episode<MAX_EPISODES:\n",
    "    our_machine.run()\n",
    "our_machine.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "a=np.array([[1,2,7],[3,4,5]])\n",
    "b=np.array([0,0,0,0,0,0])\n",
    "for i in range(2):\n",
    "    b[0+3*i:3+3*i]=a[i]\n",
    "print(b[b.argmax()])\n",
    "print(b.shape)\n",
    "x_test = np.zeros((1, 16))\n",
    "print(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pyqtgraph as pg\n",
    "import numpy as np\n",
    "x = np.arange(1000)\n",
    "y = np.random.normal(size=(3, 1000))\n",
    "plotWidget = pg.plot(title=\"Three plot curves\")\n",
    "for i in range(3):\n",
    "    plotWidget.plot(x, y[i], pen=(i,3))  ## setting pen=(i,3) automaticaly creates three different-colored pens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../logs/test.txt', 'w') as f:\n",
    "    s=\"test\"\n",
    "    f.write(s)\n",
    "    f.write(s)\n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('../logs/log.csv',newline='') as csvfile:\n",
    "    reader=csv.reader(csvfile)\n",
    "    data=list(reader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "\n",
    "with open('../logs/log.csv',newline='') as csvfile:\n",
    "    reader=csv.reader(csvfile)\n",
    "    # Transform reader to array\n",
    "    data=list(reader) \n",
    "    # Allocate arrays\n",
    "    x=[]\n",
    "    y=[]\n",
    "    # Get rid of labels\n",
    "    a=data.pop(0)\n",
    "    for row in data:\n",
    "        # Search for game lost\n",
    "        if row[10]==\"True\": # Needed because it's read as a string and not a bool\n",
    "            x.append(row[0]) # Episode\n",
    "            y.append(row[7]) # Total score     \n",
    "    # Plot results\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x=[[1,2],[3,4],[5,6]]\n",
    "\n",
    "y=np.zeros(len(x))\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
